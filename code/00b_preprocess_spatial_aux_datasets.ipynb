{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import xarray as xr\n",
    "import rioxarray as rio\n",
    "import numpy as np\n",
    "from rasterio.enums import Resampling\n",
    "from utils import *\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is intended to preprocess auxiliary datasets to bring them to the same spatial resolution of the highest resolution data source in our analysis, which is 0.1˚ x 0.1˚ (used in [Xu et al. 2021](https://www.science.org/doi/10.1126/sciadv.abe9829)).\n",
    "\n",
    "There are three main steps performed in this script:\n",
    "1. create a gridded land area map from the ESA CCI land cover data\n",
    "\n",
    "2. convert the ESA CCI land cover data into three land cover classes: forest, cropland, and grassland based on the definitions of [Tagesson et al. 2020](https://www.nature.com/articles/s41559-019-1090-0)\n",
    "\n",
    "3. Preprocess the Song et al. (2018) dataset\n",
    "\n",
    "4. Preprocess the Ma et al. (2021) dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create land area map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the 2016 land cover data\n",
    "ESA_CCI_2016 = rio.open_rasterio(f'../data/land_cover/ESA_CCI/C3S-LC-L4-LCCS-Map-300m-P1Y-2016-v2.1.1.nc',masked=True,chunks='auto',variable='lccs_class')['lccs_class']\n",
    "\n",
    "# set CRS for file\n",
    "ESA_CCI_2016.rio.write_crs(4326,inplace=True);\n",
    "\n",
    "# drop the time dimension\n",
    "ESA_CCI_2016 = ESA_CCI_2016.drop_vars('time').squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask all areas that are not water (210)\n",
    "land = (ESA_CCI_2016 != 210).astype(float)\n",
    "\n",
    "# set nodata value to nan\n",
    "land.rio.set_nodata(np.nan,inplace=True)\n",
    "\n",
    "# calculate the area of each pixel\n",
    "area = calc_pixel_area(land)\n",
    "\n",
    "# calculate the total land surface area and reproject to 0.1 degree resolution\n",
    "land_surface_area = (land*area).rio.set_nodata(np.nan).rio.reproject(land.rio.crs,shape=[1800,3600],resampling=Resampling.sum)\n",
    "\n",
    "# save the land surface area output to a netcdf file\n",
    "land_surface_area.to_netcdf('../results/00_preprocessing/land_surface_area.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess ESA CCI land cover data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the Xu et al. 2021 biomass data to use as a target projection and resolution\n",
    "xu_data = rio.open_rasterio('../data/biomass/xu_et_al_2021/test10a_cd_ab_pred_corr_2000_2019_v2.tif')[0,:,:]\n",
    "\n",
    "# define function to preprocess the ESA CCI data\n",
    "def process_CCI(raster: xr.DataArray) -> xr.DataArray:\n",
    "    '''\n",
    "    Preprocess the ESA CCI land cover data\n",
    "\n",
    "    Parameters:\n",
    "    raster (xarray.DataArray): raster to preprocess\n",
    "\n",
    "    Returns:\n",
    "    xarray.DataArray: preprocessed raster of size (1800,3600,3) with the surface area of each land cover class (forest, cropland, and shrubland) in each pixel\n",
    "    '''\n",
    "    ## Using the definitions in Tagesson et al. DOI: 10.1038/s41559-019-1090-0\n",
    "    ## Categories:\n",
    "        ## forest - 50,60,61,62,70,71,72,80,81,82,90,100,160,170 + 0.1*151 + 0.03*150\n",
    "        ## cropland/grassland - 10,11,20,30,110,130 + 0.1*153 + 0.03*150\n",
    "        ## shrubland - 12, 40, 120, 121,122,140,180 + 0.1*152 + 0.03*150\n",
    "        ## bare - 190, 200,201,202,210,220\n",
    "    \n",
    "    # calculate surface area\n",
    "    surface_area = calc_pixel_area(raster)\n",
    "\n",
    "    # define the land cover classes\n",
    "    cropland = raster.isin([10,11,20,30,110,130]) + 0.1 * (raster== 153) + 0.03 * (raster==150)\n",
    "    forest = raster.isin([50,60,61,62,70,71,72,80,81,82,90,100,160,170]) + 0.1 * (raster== 151) + 0.03 * (raster==150)\n",
    "    shrub = raster.isin([12, 40, 120, 121,122,140,180]) + 0.1 * (raster== 152) + 0.03 * (raster==150)\n",
    "    lcs = [cropland,forest,shrub]\n",
    "    \n",
    "    for i in range(len(lcs)):\n",
    "        # lcs[i] =  (lcs[i]*surface_area).rio.reproject_match(xu_data,resampling=Resampling.sum)\n",
    "        lcs[i] =  down_sample(lcs[i]*surface_area,x_factor=36,y_factor=36,stat='sum')\n",
    "\n",
    "    result = xr.concat(lcs,dim='landcover')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/29 [01:39<46:36, 99.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/29 [03:39<50:13, 111.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/29 [05:02<42:35, 98.28s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 4/29 [06:36<40:15, 96.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/29 [07:59<36:44, 91.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6/29 [09:24<34:14, 89.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 7/29 [10:51<32:29, 88.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 8/29 [12:15<30:30, 87.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 9/29 [13:46<29:26, 88.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 10/29 [15:06<27:11, 85.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 11/29 [16:29<25:27, 84.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1992\n",
      "1999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 13/29 [17:50<17:08, 64.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 14/29 [19:21<17:45, 71.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 15/29 [20:44<17:15, 74.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 16/29 [22:15<17:02, 78.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 17/29 [23:38<15:58, 79.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 18/29 [25:00<14:47, 80.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 19/29 [26:24<13:34, 81.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 20/29 [27:43<12:08, 80.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 21/29 [29:11<11:02, 82.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 22/29 [30:40<09:52, 84.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 23/29 [32:04<08:26, 84.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 24/29 [33:26<06:59, 83.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 25/29 [34:48<05:32, 83.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 26/29 [36:08<04:06, 82.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 27/29 [37:29<02:43, 81.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 28/29 [38:48<01:21, 81.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [40:09<00:00, 83.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# find all ESA CCI land cover files\n",
    "files = glob('../data/land_cover/ESA_CCI/*.nc')\n",
    "\n",
    "# load the land cover data\n",
    "for file in tqdm(files):\n",
    "    \n",
    "    # check if output file already exists\n",
    "    year = file.split(\"/\")[-1].split(\".\")[0].split('-')[-2]\n",
    "    print(year)\n",
    "    if glob(f'../results/00_preprocessing/ESA_CCI_landcover_processed_{year}.nc'):\n",
    "        continue\n",
    "    \n",
    "    # open the file\n",
    "    da = rio.open_rasterio(file,masked=True,chunks='auto',variable='lccs_class')['lccs_class']\n",
    "    \n",
    "    # set the CRS\n",
    "    da = da.rio.write_crs(4326,inplace=True)\n",
    "    \n",
    "    # process the file\n",
    "    res = process_CCI(da)\n",
    "    \n",
    "    # add landcover as a coordinate\n",
    "    res['landcover'] = ['cropland','forest','shrubland']\n",
    "\n",
    "    # change name of the variable\n",
    "    res.name = 'ESA_CCI_landcover_processed'\n",
    "\n",
    "    # save the results\n",
    "    res.to_netcdf(f'../results/00_preprocessing/ESA_CCI_landcover_processed_{year}.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Song et al. (2018) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ESA CCI landcover data in order to reproject to the Song et al. data to its resolution\n",
    "files = glob('../results/00_preprocessing/ESA_CCI_landcover_processed_*.nc')\n",
    "CCI_data = xr.open_dataset(files[0])['ESA_CCI_landcover_processed']\n",
    "CCI_data.rio.write_crs('EPSG:4326',inplace=True)\n",
    "\n",
    "\n",
    "# Load Song et al. data\n",
    "files = glob(f'../data/land_cover/song_et_al_2018/VCF*.tif')\n",
    "song_data = xr.concat([rio.open_rasterio(x,masked=True,chunks='auto').rio.reproject_match(CCI_data) for x in files],dim='time')\n",
    "\n",
    "# get the years\n",
    "years = [int(f.split('/')[-1].split('_')[1][:4]) for f in files]\n",
    "song_data['time'] = years\n",
    "\n",
    "# rename the band dimension to landcover\n",
    "song_data = song_data.rename({'band':'landcover'})\n",
    "\n",
    "# convert units from % to fraction\n",
    "song_data = song_data/100\n",
    "\n",
    "# remove the \"bare land\" class\n",
    "song_data = song_data[:,:2,:,:]\n",
    "\n",
    "# name landcover as a coordinate\n",
    "song_data['landcover'] = ['forest','nonforest']\n",
    "\n",
    "# take only data that is greater than 0 and set nodata value to nan\n",
    "song_data = song_data.where(song_data>0).rio.set_nodata(np.nan)\n",
    "\n",
    "# sort by time\n",
    "song_data = song_data.sortby('time')\n",
    "\n",
    "song_data.name = 'Song et al. 2018'\n",
    "\n",
    "# interpolate missing years\n",
    "song_data = song_data.interp(time=np.arange(1982,2020))\n",
    "\n",
    "# take the years 1992 to 2019\n",
    "song_data = song_data.sel(time=slice(1992,2019))\n",
    "\n",
    "# transpose dimensions to be in the order landcover,time,y,x\n",
    "song_data = song_data.transpose('landcover','time','y','x')\n",
    "\n",
    "# save the results\n",
    "song_data.to_netcdf('../results/00_preprocessing/song_et_al_landcover_processed.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Ma et al. (2021) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the landcovers to use\n",
    "landcover_types = ['forest','shrub','grass']\n",
    "\n",
    "# load data and merge it into one file\n",
    "ma_data = xr.concat([xr.concat([rio.open_rasterio(x,masked=True,chunks='auto').sel(band=1) for x in glob(f'../data/RMF/ma_et_al_2021/{type}*.tif')],dim='x') for type in landcover_types],dim='landcover')\n",
    "ma_data['landcover'] = landcover_types\n",
    "\n",
    "# resample the data to the same resolution as the Xu et al. data\n",
    "ma_data = ma_data.rio.reproject(ma_data.rio.crs,shape=[1800,3600],resampling=Resampling.nearest)\n",
    "\n",
    "# name the data\n",
    "ma_data.name = 'Ma et al. 2021'\n",
    "\n",
    "# save the data\n",
    "ma_data.to_netcdf('../results/00_preprocessing/ma_et_al_processed.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and merge it into one file\n",
    "ma_data = xr.concat([rio.open_rasterio(x,masked=True,chunks='auto').sel(band=1) for x in glob(f'../data/RMF/ma_et_al_2021/rmf_all*.tif')],dim='x')\n",
    "\n",
    "# resample the data to the same resolution as the Xu et al. data\n",
    "ma_data = ma_data.rio.reproject(ma_data.rio.crs,shape=[1800,3600],resampling=Resampling.nearest)\n",
    "\n",
    "# name the data\n",
    "ma_data.name = 'Ma et al. 2021'\n",
    "\n",
    "# save the data\n",
    "ma_data.to_netcdf('../results/00_preprocessing/ma_et_al_processed_all.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Huang et al. (2021) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and merge into one DataArray\n",
    "files = glob('../data/RMF/huang_et_al_2021/data_code_to_submit/pergridarea_*.nc')\n",
    "huang_data = xr.concat([rio.open_rasterio(x,masked=True,chunks='auto').sel(band=1) for x in files],dim='veg_part')\n",
    "\n",
    "# name the different parts of the vegetation\n",
    "huang_data['veg_part'] = ['shoot','root']\n",
    "\n",
    "# calculate the RMF from Huang\n",
    "huang_data = huang_data.sel(veg_part='root')/huang_data.sum(dim='veg_part')\n",
    "\n",
    "# set CRS\n",
    "huang_data.rio.write_crs(4326,inplace=True)\n",
    "\n",
    "# set no data to nan\n",
    "huang_data = huang_data.rio.set_nodata(np.nan)\n",
    "\n",
    "# resample the data to the same resolution as the Xu et al. data\n",
    "huang_data = huang_data.rio.reproject(huang_data.rio.crs,shape=[1800,3600],resampling=Resampling.average,nodata=np.nan)\n",
    "\n",
    "# name the DataArray\n",
    "huang_data.name = 'Huang et al. 2021'\n",
    "\n",
    "# save the data\n",
    "huang_data.to_netcdf('../results/00_preprocessing/huang_et_al_processed.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and merge into one DataArray\n",
    "files = glob('../data/RMF/huang_et_al_2021/data_code_to_submit/pergridarea_*.nc')\n",
    "huang_data = xr.concat([rio.open_rasterio(x,masked=True,chunks='auto').sel(band=1) for x in files],dim='veg_part')\n",
    "\n",
    "# name the different parts of the vegetation\n",
    "huang_data['veg_part'] = ['shoot','root']\n",
    "\n",
    "# calculate the RMF from Huang\n",
    "huang_data = huang_data.sel(veg_part='root')/huang_data.sum(dim='veg_part')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
