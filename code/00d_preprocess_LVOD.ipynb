{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import rioxarray as rio\n",
    "import xarray as xr\n",
    "from rasterio.enums import Resampling\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main aim of this preprocessing step is to:\n",
    "1. Perform different corrections for the L-VOD data to reduce the impact of Radio Frequency Interference (RFI).\n",
    "\n",
    "2. Convert the data from an EASE2 grid to a regular grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Correct L-VOD data for RFI \n",
    "\n",
    "One of the limitations of the L-VOD data is that it suffers from Radio Frequency Interference. That leads to time varying coverage of the data. The main aim of this preprocessing step is to reduce the impact of this effect.\n",
    "\n",
    "In our analysis, we rely on the approach used in [Yang et al. 2023](https://www.nature.com/articles/s41561-023-01274-4).\n",
    "\n",
    "The Yang et al. 2023 approach is based on the following steps:\n",
    "\n",
    "1. Calculate a long-term trend using a curve fitting method that has been used to filter and smooth CO2 measurements by NOAA\n",
    "\n",
    "2. Correct for RFI by identifying invalid pixels based on the following conditions:\n",
    "    - if the absolute difference between the ASC and DESC modes is greater than 10% of the mean of the the two\n",
    "\n",
    "    - if either of the ASC and DESC modes is not null and the ASC_DESC mode is less than 90% of the mean of the ASC and DESC modes\n",
    "    \n",
    "    The method to correct for invalid pixels is to use the maximum of the ASC and DESC modes for invalid pixels. \n",
    "\n",
    "Because this analysis produces an average rate of change for each pixel, but our pipeline works with estimates of the stocks at different years, we combine the estimates of the stock change with the estimates of the stocks at the year 2019 to infer the stocks and the year 2010. The output of the analysis is thus stocks at two time periods - 2010 and 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def correct_invalid_RFI_pixels(data_yr:xr.DataArray,data_other_yr:xr.DataArray) -> xr.DataArray:\n",
    "    '''\n",
    "    Get valid value and year for each pixel. Pixels that suffer from Radio Frequency Interference (RFI) are identified based on the following conditions:\n",
    "    - if the absolute difference between the ASC and DESC modes is greater than 10% of the mean of the the two\n",
    "    - if either of the ASC and DESC modes is not null and the ASC_DESC mode is less than 90% of the mean of the ASC and DESC modes\n",
    "    \n",
    "    The method to correct for invalid pixels is to use the maximum of the ASC and DESC modes for invalid pixels. \n",
    "\n",
    "    Parameters:\n",
    "    data_yr (xarray.DataArray): data for the year\n",
    "    data_other_yr (xarray.DataArray): data for the next year \n",
    "\n",
    "    Returns:\n",
    "    final_data (xarray.DataArray): corrected data\n",
    "    '''\n",
    "\n",
    "    # set up rultes for invalid pixels\n",
    "    # if the absolute difference between the ASC and DESC modes is greater than 10% of the mean of the ASC and DESC modes\n",
    "    mask1 = (np.abs(data_yr[1,:,:]-data_yr[2,:,:]) > data_yr[1:,:,:].mean(dim='type')*0.1)\n",
    "\n",
    "    # if either of the ASC and DESC modes is not null and the ASC_DESC mode is less than 90% of the mean of the ASC and DESC modes\n",
    "    mask2 = data_yr[1:,:,:].isnull().any(dim='type') & (data_yr[0,:,:] < data_yr[1:,:,:].mean(dim='type')*0.9)\n",
    "\n",
    "    # combine the two masks\n",
    "    cond = mask1 | mask2\n",
    "\n",
    "    # if the condition is true (for invalid pixels), set the data as the maximum of ASC and DESC, otherwise keep the ASC_DESC mode value\n",
    "    final_data = xr.where(cond,data_yr[1:,:,:].max(dim='type'),data_yr[0,:,:])\n",
    "    \n",
    "    return final_data\n",
    "\n",
    "def calculate_trend(ds: xr.Dataset,calibration_mode='') -> xr.DataArray:\n",
    "    '''\n",
    "    Calculate the trend of the data\n",
    "\n",
    "    Parameters:\n",
    "    ds (xarray.Dataset): data to calculate the trend for\n",
    "    calibration_mode (str): mode to use for calibration of L-VOD to biomass (either '', 'min' or 'max')\n",
    "\n",
    "    Returns:\n",
    "    trend xarray.DataArray: trend of the data (in units of MgC/ha/yr)\n",
    "    '''\n",
    "\n",
    "    # make sure the calibration mode is either None, 'min' or 'max'\n",
    "    assert calibration_mode in ['','min','max']\n",
    "    modes = ['AGC_ASC_DESC','AGC_ASC','AGC_DESC']\n",
    "    modes = [m+calibration_mode for m in modes]\n",
    "\n",
    "\n",
    "    # find the first time in which a pixel has non nan value in the time dimension for ASC_DESC\n",
    "\n",
    "    # multiply each non-null value by its index in the time dimension\n",
    "    time_inds = (ds['AGC_ASC_DESC'].notnull().transpose('lat','lon','time') * np.arange(1,12,dtype=int))\n",
    "\n",
    "    # replace zeros with 13 and find min along time axis\n",
    "    ASC_DESC_start = xr.where(time_inds == 0,13,time_inds).min(dim='time')\n",
    "\n",
    "    # replace 13 with nan\n",
    "    ASC_DESC_start = xr.where(ASC_DESC_start == 13, np.nan, ASC_DESC_start) -1\n",
    "\n",
    "    # fill na for indexing\n",
    "    ASC_DESC_start_filled = ASC_DESC_start.fillna(0).astype(int)\n",
    "\n",
    "    # calculate the first valid value for each of the three acuisition modes\n",
    "    start_data = xr.concat([ds[i].isel(time=ASC_DESC_start_filled) for i in modes],dim='type')\n",
    "\n",
    "    # calculate the year after the first valid value for each of the three acuisition modes\n",
    "    ASC_DESC_start_filled_next_yr = xr.where(ASC_DESC_start_filled<10,ASC_DESC_start_filled+1,ASC_DESC_start_filled)\n",
    "\n",
    "    # calculate the value for the year after the first valid year for each of the three acuisition modes\n",
    "    start_data_next_yr = xr.concat([ds[i].isel(time=ASC_DESC_start_filled_next_yr) for i in modes],dim='type')\n",
    "\n",
    "    # set the end year to 2019\n",
    "    end_yr = 9*xr.ones_like(ASC_DESC_start_filled)\n",
    "\n",
    "    # calculate the last valid value for each of the three acuisition modes\n",
    "    end_data = xr.concat([ds[i].isel(time=end_yr) for i in modes],dim='type')\n",
    "\n",
    "    # calculate the year before the last valid value for each of the three acuisition modes\n",
    "    end_data_prev = xr.concat([ds[i].isel(time=end_yr-1) for i in modes],dim='type')\n",
    "\n",
    "    # correct the invalid pixels for the start and end years\n",
    "    start_data_final = correct_invalid_RFI_pixels(start_data,start_data_next_yr)\n",
    "    end_data_final = correct_invalid_RFI_pixels(end_data,end_data_prev)\n",
    "\n",
    "    # filter the data to only include pixels that have at least one non-null value across the time series and have a start year less than 2018\n",
    "    cond = ds['AGC_ASC_DESC'].notnull().any(dim='time') & (ASC_DESC_start < 8)\n",
    "    start_data_final = xr.where(cond,start_data_final,np.nan)\n",
    "    end_data_final = xr.where(cond,end_data_final,np.nan)\n",
    "\n",
    "    # calculate the trend\n",
    "    trend = ((end_data_final-start_data_final)/(end_yr-ASC_DESC_start))\n",
    "\n",
    "    return trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the L-VOD data\n",
    "ds = xr.open_dataset('../data/biomass_estimates/LVOD/transfer_7684148_files_1514bd66/AGC_vod_annual_NOAA_Trend.nc',decode_times=False)\n",
    "\n",
    "# create a corrected xr.Dataset with the same dimensions as the original dataset, but only for 2010 and 2019 in the time dimension\n",
    "yang_correction = ds.drop_vars(['AGC_ASC','AGC_ASCmin','AGC_ASCmax','AGC_DESC','AGC_DESCmin','AGC_DESCmax']).sel(time=[2010,2019])\n",
    "\n",
    "# for each calibration mode\n",
    "for m in ['','min','max']:\n",
    "\n",
    "    # calculate the trend for the three calibration modes\n",
    "    correction = calculate_trend(ds,calibration_mode=m)\n",
    "\n",
    "    # take the data for the year 2019 in places where we could infer the trend\n",
    "    yang_correction['AGC_ASC_DESC'+m] = yang_correction['AGC_ASC_DESC'+m].where(correction.notnull())\n",
    "    \n",
    "    # calculate the correction for the year 2010\n",
    "    first_year = yang_correction['AGC_ASC_DESC'+m][-1,:,:] - correction*9\n",
    "    yang_correction['AGC_ASC_DESC'+m][0,:,:] = xr.where(first_year>0,first_year,np.nan)\n",
    "\n",
    "# save the corrected data\n",
    "yang_correction.to_netcdf('../results/00_preprocessing/AGC_vod_annual_NOAA_Trend_corrected.nc')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Convert L-VOD maps from EASE2 grid to regular grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file size is 1388, 584\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1388, 584\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1388, 584\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1388, 584\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1388, 584\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1388, 584\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1388, 584\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1388, 584\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1388, 584\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1388, 584\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1388, 584\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1388, 584\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1388, 584\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1388, 584\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1388, 584\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1388, 584\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1388, 584\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1388, 584\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "vars = ['AGC_ASC_DESC','AGC_ASC_DESCmin','AGC_ASC_DESCmax']\n",
    "\n",
    "for var in vars:\n",
    "    # first transform the coords of the netcdf files to meters as the projection is in meters\n",
    "    # based on https://gis.stackexchange.com/questions/376463/gdal-translate-outputs-coordinates-in-metres-but-i-need-degrees\n",
    "    !gdal_translate -of NetCDF -a_nodata -9999 -a_ullr -17367530.45 7314540.83 17367530.45 -7314540.83 -a_srs \"+proj=cea +lon_0=0 +lat_ts=30 +x_0=0 +y_0=0 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\" NETCDF:\"../results/00_preprocessing/AGC_vod_annual_NOAA_Trend_corrected.nc\":{var} \"../results/00_preprocessing/AGC_vod_annual_NOAA_Trend_corrected_\"{var}\"_meters.nc\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob('../results/00_preprocessing/AGC_vod_annual_NOAA_Trend_corrected_*meters.nc'))\n",
    "def load_LVOD(file):\n",
    "    # load file\n",
    "    LVOD = rio.open_rasterio(file,decode_times=False,masked=True)\n",
    "\n",
    "    # get the crs\n",
    "    crs = LVOD.rio.crs\n",
    "\n",
    "    # set crs\n",
    "    LVOD.rio.write_crs(crs,inplace=True)\n",
    "\n",
    "    # reproject to epsg:4326\n",
    "    LVOD = LVOD.rio.reproject('epsg:4326',resampling=Resampling.nearest)\n",
    "    \n",
    "    return LVOD\n",
    "\n",
    "# run for all files\n",
    "das = list(map(load_LVOD,files))\n",
    "\n",
    "# concat all dataarrays\n",
    "das = xr.concat(das,dim='method')\n",
    "\n",
    "das['method'] = var_names = [f.split('/')[-1].split('_corrected_')[-1].split('_meters')[0] for f in files]\n",
    "\n",
    "# save to netcdf\n",
    "das.to_netcdf('../data/biomass_estimates/LVOD/AGC_vod_annual_NOAA_Trend_corrected_lat_lon_merged.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
